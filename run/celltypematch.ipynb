{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To download the cell type annotations:\n",
    "`aws s3 cp s3://openproblems-bio/public/post_competition/openproblems_bmmc_cite_complete.h5ad ./datasets/post_competition/ --no-sign-request`\n",
    "`aws s3 cp s3://openproblems-bio/public/post_competition/openproblems_bmmc_multiome_complete.h5ad ./datasets/post_competition/ --no-sign-request`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import anndata as ad\n",
    "import torch\n",
    "import numpy\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TASK = 'GEX2ADT'\n",
    "TASK = 'GEX2ATAC'\n",
    "DATASET_PATH = \"datasets\"\n",
    "PREDICTION_PATH = \"pretrain/defaultGEX2ATAC.h5ad\"\n",
    "# PREDICTION_PATH = \"pretrainNovel/NovelGEX2ATAC.h5ad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if TASK == 'GEX2ADT':\n",
    "    test_path = os.path.join(DATASET_PATH, \"openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna\"\n",
    "                                                \".censor_dataset.output_\")\n",
    "    completedata_path = os.path.join(DATASET_PATH, \"post_competition/openproblems_bmmc_cite_complete.h5ad\")\n",
    "elif TASK == 'GEX2ATAC':\n",
    "    test_path = os.path.join(DATASET_PATH, \"openproblems_bmmc_multiome_phase2_rna\"\n",
    "                                                \"/openproblems_bmmc_multiome_phase2_rna.censor_dataset.output_\")\n",
    "    completedata_path = os.path.join(DATASET_PATH, \"post_competition/openproblems_bmmc_multiome_complete.h5ad\")\n",
    "else:\n",
    "    raise ValueError('Unknown task: ' + TASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "par = {\n",
    "        \"input_mod1\": f\"{test_path}test_mod1.h5ad\",\n",
    "        \"input_mod2\": f\"{test_path}test_mod2.h5ad\",\n",
    "        \"input_complete\": completedata_path,\n",
    "        \"input_test_sol\": f\"{test_path}test_sol.h5ad\",\n",
    "        \"input_test_prediction\": PREDICTION_PATH,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_mod1 = ad.read_h5ad(par[\"input_mod1\"])\n",
    "input_mod2 = ad.read_h5ad(par[\"input_mod2\"])\n",
    "complete = ad.read_h5ad(par[\"input_complete\"])\n",
    "prediction_test = ad.read_h5ad(par[\"input_test_prediction\"])\n",
    "sol_test = ad.read_h5ad(par[\"input_test_sol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for PBMC\n",
    "input_mod1 = ad.read_h5ad(\"../datasets/PBMC/glue_processed/test_mod1.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PREDICTION_PATH = \"pretrain/pbmc1GEX2ATAC.h5ad\"\n",
    "prediction_test = ad.read_h5ad(\"../\" + PREDICTION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mod1_withcelltype = input_mod1\n",
    "mod1_withcelltype.obs[\"cell_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def obs_fea(adata):\n",
    "    print(f\"The data has {adata.n_obs} observations and {adata.n_vars} features.\")\n",
    "\n",
    "obs_fea(prediction_test)\n",
    "obs_fea(sol_test)\n",
    "obs_fea(complete)\n",
    "obs_fea(input_mod1)\n",
    "obs_fea(input_mod2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_mod2.obs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mod1_withcelltype = complete[input_mod1.obs_names]\n",
    "mod1_withcelltype.obs[\"cell_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "celltypes = mod1_withcelltype.obs[\"cell_type\"].cat.categories.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "celltype2idx = dict([(celltype, idx) for idx, celltype in enumerate(celltypes)])\n",
    "celltype2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if type(prediction_test.X) != numpy.ndarray:\n",
    "    X = prediction_test.X.toarray()\n",
    "else:\n",
    "    X = prediction_test.X\n",
    "X = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Xsol = torch.tensor(sol_test.X.toarray())\n",
    "Xsol.argmax(1)\n",
    "# Order the columns of the prediction matrix so that the perfect prediction is the identity matrix\n",
    "X = X[:, Xsol.argmax(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "perm = mod1_withcelltype.obs[\"cell_type\"].to_frame()\n",
    "print(perm.value_counts())\n",
    "perm.insert(1, \"idx\", list(range(X.shape[0])))\n",
    "perm = perm.sort_values(\"cell_type\")\n",
    "perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "block_idxs = [0]\n",
    "for i in tqdm(range(1, len(perm))):\n",
    "    if perm.iloc[i].cell_type != perm.iloc[i-1].cell_type:\n",
    "        block_idxs.append(i)\n",
    "block_idxs.append(len(perm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(block_idxs)\n",
    "len(block_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Permute X such that it is a block diagonal matrix with 1 block per cell type\n",
    "X = X[perm[\"idx\"]][:, perm[\"idx\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask = torch.zeros_like(X)\n",
    "for i in tqdm(range(1, len(block_idxs))):\n",
    "    idx_start = block_idxs[i-1]\n",
    "    idx_end = block_idxs[i]\n",
    "    mask[idx_start:idx_end, idx_start:idx_end] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X = Xsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Xsoft = X\n",
    "print(X.sum())\n",
    "X = X.clip(min=0)\n",
    "print(X.sum())\n",
    "mx = torch.max(X, dim=1, keepdim=True).values\n",
    "X = (mx == X).float()   # convert to a hard matching\n",
    "logits_row_sums = X.sum(dim=1)\n",
    "print(logits_row_sums)\n",
    "X = torch.div(X, logits_row_sums)\n",
    "print(X.shape, X.sum())\n",
    "\n",
    "scoreX = X.mul(mask)\n",
    "print(scoreX.sum())\n",
    "\n",
    "cell_type_score = scoreX.sum() / scoreX.shape[0]\n",
    "\n",
    "print(\"Cell type matching competition score\", cell_type_score.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(block_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "block_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "per_celltype_scores = []\n",
    "for i in range(1, len(block_idxs)):\n",
    "    idx_start = block_idxs[i-1]\n",
    "    idx_end = block_idxs[i]\n",
    "    n_cells = idx_end - idx_start\n",
    "    celltype = perm.iloc[idx_start].cell_type\n",
    "    print(celltype, \"n_cells:\", n_cells)\n",
    "    acc_celltype = (scoreX[idx_start:idx_end].sum()/n_cells).item()\n",
    "    print(acc_celltype)\n",
    "    per_celltype_scores.append([celltype, n_cells, acc_celltype])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "per_celltype_scores_df = pd.DataFrame(columns=[\"celltype\", \"n_cells\", \"acc_celltype\"], data=per_celltype_scores)\n",
    "print(per_celltype_scores_df.sort_values(\"acc_celltype\"))\n",
    "print(\"non balanced acc\", numpy.mean(per_celltype_scores_df.acc_celltype.values))\n",
    "print(\"tot cell\", numpy.sum(per_celltype_scores_df.n_cells.values))\n",
    "per_celltype_scores_df.to_csv(\"per_celltype_scores_novel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def idx2celltypeidx(idx):\n",
    "    return celltype2idx[perm.iloc[idx].cell_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_celltype_true = []\n",
    "y_idx_pred = torch.argmax(X, dim=1).numpy()\n",
    "y_celltype_pred = [idx2celltypeidx(idx) for idx in y_idx_pred]\n",
    "sum=0\n",
    "for i in range(1, len(block_idxs)):\n",
    "    idx_start = block_idxs[i-1]\n",
    "    idx_end = block_idxs[i]\n",
    "    n_cells = idx_end - idx_start\n",
    "    print(n_cells)\n",
    "    sum += n_cells\n",
    "    celltype = perm.iloc[idx_start].cell_type\n",
    "    y_celltype_true += [i-1 for c in range(n_cells)]\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_celltype_true, y_celltype_pred, normalize='true')\n",
    "numpy.sum(cm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=celltypes)\n",
    "# plt.figure(figsize=(10,10))\n",
    "# disp.plot(xticks_rotation='vertical', values_format='.1f', include_values=False, cmap='viridis')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "fig, ax = plt.subplots(figsize=(13,10))\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', xticklabels=celltypes, yticklabels=celltypes, square=True)\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)\n",
    "fig.savefig('confusion_percelltype_novel.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoreX.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(mask[::100, ::100].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(scoreX[::100, ::100].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(torch.pow(Xsoft[::100, ::100], 0.15).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best = 0\n",
    "for p in torch.arange(0.05, 2, 0.05):\n",
    "    print(p)\n",
    "    X=torch.pow(Xsoft, p)\n",
    "    # Xsoft = X\n",
    "    print(X.sum())\n",
    "    X = X.clip(min=0)\n",
    "    print(X.sum())\n",
    "    mx = torch.max(X, dim=0, keepdim=True).values\n",
    "    # X = (mx == X).float()   # convert to a hard matching\n",
    "    logits_row_sums = X.sum(dim=0)\n",
    "    print(logits_row_sums)\n",
    "    X = torch.div(X, logits_row_sums)\n",
    "    print(X.shape, X.sum().item())\n",
    "\n",
    "    scoreX = X.mul(mask)\n",
    "    print(scoreX.sum())\n",
    "\n",
    "    cell_type_score = scoreX.sum() / scoreX.shape[0]\n",
    "\n",
    "    print(\"Cell type matching competition score\", cell_type_score.item())\n",
    "    if cell_type_score.item() > best:\n",
    "        best = cell_type_score.item()\n",
    "        best_p = p\n",
    "        print(\"best p:\", best_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(scoreX.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}